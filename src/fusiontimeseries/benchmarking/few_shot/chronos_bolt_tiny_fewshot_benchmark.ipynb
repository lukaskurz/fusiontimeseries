{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chronos-Bolt-Tiny Few-Shot In-Context Learning Benchmark\n",
    "\n",
    "This notebook benchmarks Chronos-Bolt-Tiny's few-shot ICL capabilities.\n",
    "\n",
    "**Key differences from Chronos-2:**\n",
    "- Smaller model (tiny variant)\n",
    "- Input shape: `[1, context_len]` (no channel dimension)\n",
    "- Same ICL format: context + target pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from chronos import ChronosBoltPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fusiontimeseries.benchmarking.zero_shot.benchmark_utils import (\n",
    "    BenchmarkDataProvider,\n",
    "    IN_DISTRIBUTION_ITERATIONS,\n",
    "    OUT_OF_DISTRIBUTION_ITERATIONS,\n",
    "    Utils,\n",
    "    rmse_with_standard_error,\n",
    ")\n",
    "from fusiontimeseries.benchmarking.few_shot.few_shot_utils import (\n",
    "    FewShotConfig,\n",
    "    create_example_pool,\n",
    "    select_examples_random,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: k=3, seed=42\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "K_SHOT = 3  # Change to test different k values: 1, 3, 5, 10\n",
    "\n",
    "config = FewShotConfig(\n",
    "    model_slug=\"amazon/chronos-bolt-tiny\",\n",
    "    model_prediction_length=64,\n",
    "    start_context_length=80,\n",
    "    relevant_prediction_tail=80,\n",
    "    k_shot=K_SHOT,\n",
    "    random_seed=42,\n",
    ")\n",
    "print(f\"Configuration: k={config.k_shot}, seed={config.random_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on device: mps\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "provider = BenchmarkDataProvider()\n",
    "pipeline: ChronosBoltPipeline = ChronosBoltPipeline.from_pretrained(\n",
    "    pretrained_model_name_or_path=config.model_slug,\n",
    "    device_map=config.device,\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "print(f\"Model loaded on device: {config.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created example pool with 246 traces (excluded 6 test IDs)\n",
      "✓ Example pool: 246 traces, no test leakage\n"
     ]
    }
   ],
   "source": [
    "# Create example pool\n",
    "test_ids = {8, 115, 131, 148, 235, 262}\n",
    "example_pool = create_example_pool(exclude_ids=test_ids)\n",
    "pool_ids = {ex.trace_id for ex in example_pool}\n",
    "assert not (pool_ids & test_ids), \"ERROR: Test IDs found in example pool!\"\n",
    "print(f\"✓ Example pool: {len(example_pool)} traces, no test leakage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fewshot_autoregressive_forecast(\n",
    "    trace: np.ndarray,\n",
    "    examples: list,\n",
    "    config: FewShotConfig,\n",
    "    pipeline: ChronosBoltPipeline,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Few-shot autoregressive forecast for Chronos-Bolt-Tiny.\"\"\"\n",
    "    trace_length = trace.shape[0]\n",
    "    \n",
    "    # Normalize examples independently\n",
    "    normalized_examples = []\n",
    "    for ex in examples:\n",
    "        ex_scaler = StandardScaler()\n",
    "        normed_ctx = ex_scaler.fit_transform(ex.context_array.reshape(-1, 1)).squeeze()\n",
    "        normed_tgt = ex_scaler.transform(ex.target_array.reshape(-1, 1)).squeeze()\n",
    "        normalized_examples.append({\"context\": normed_ctx, \"target\": normed_tgt})\n",
    "    \n",
    "    # Normalize query\n",
    "    query_scaler = StandardScaler()\n",
    "    initial_query_context = trace[:config.start_context_length]\n",
    "    normed_query_ctx = query_scaler.fit_transform(\n",
    "        initial_query_context.reshape(-1, 1)\n",
    "    ).squeeze()\n",
    "    \n",
    "    current_query = normed_query_ctx.copy()\n",
    "    predictions = [initial_query_context]\n",
    "    \n",
    "    # Autoregressive prediction\n",
    "    while len(np.concatenate(predictions)) < trace_length:\n",
    "        # Format ICL context\n",
    "        icl_segments = []\n",
    "        for ex_norm in normalized_examples:\n",
    "            icl_segments.append(ex_norm[\"context\"])\n",
    "            icl_segments.append(ex_norm[\"target\"])\n",
    "        icl_segments.append(current_query)\n",
    "        icl_context = np.concatenate(icl_segments)\n",
    "        \n",
    "        # Convert to tensor: [1, context_length] (no channel dimension for Chronos-Bolt)\n",
    "        ctx_tensor = torch.tensor(icl_context, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        # Predict\n",
    "        quantiles: torch.Tensor = pipeline.predict(\n",
    "            inputs=ctx_tensor.to(config.device),\n",
    "            prediction_length=config.model_prediction_length,\n",
    "        ).permute(0, 2, 1)  # [1, pred_len, n_quantiles]\n",
    "        \n",
    "        median_forecast = Utils.median_forecast(quantiles).squeeze().cpu().numpy()\n",
    "        \n",
    "        # Denormalize\n",
    "        denormed_pred = query_scaler.inverse_transform(\n",
    "            median_forecast.reshape(-1, 1)\n",
    "        ).squeeze()\n",
    "        predictions.append(denormed_pred)\n",
    "        \n",
    "        # Update context\n",
    "        extended_denormed = np.concatenate(predictions)\n",
    "        current_query = query_scaler.transform(\n",
    "            extended_denormed.reshape(-1, 1)\n",
    "        ).squeeze()\n",
    "    \n",
    "    return np.concatenate(predictions)[:trace_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ID: iteration_8_ifft\n",
      "Processing ID: iteration_115_ifft\n",
      "Processing ID: iteration_131_ifft\n",
      "Processing ID: iteration_148_ifft\n",
      "Processing ID: iteration_235_ifft\n",
      "Processing ID: iteration_262_ifft\n"
     ]
    }
   ],
   "source": [
    "# Run benchmarks\n",
    "trace_forecast = {\"in_distribution\": {}, \"out_of_distribution\": {}}\n",
    "\n",
    "for trace_id in IN_DISTRIBUTION_ITERATIONS:\n",
    "    print(f\"Processing ID: {trace_id}\")\n",
    "    trace = provider.get_id(trace_id).numpy()\n",
    "    examples = select_examples_random(example_pool, k=config.k_shot, seed=config.random_seed)\n",
    "    forecast = fewshot_autoregressive_forecast(trace, examples, config, pipeline)\n",
    "    trace_forecast[\"in_distribution\"][trace_id] = (trace, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Evaluation - compute trace means\ntrace_means = {\"in_distribution\": {\"ground_truth\": [], \"forecast\": []}, \"out_of_distribution\": {\"ground_truth\": [], \"forecast\": []}}\n\nfor trace_id, (y_true, y_pred) in trace_forecast[\"in_distribution\"].items():\n    trace_means[\"in_distribution\"][\"ground_truth\"].append(np.mean(y_true[-config.relevant_prediction_tail:]))\n    trace_means[\"in_distribution\"][\"forecast\"].append(np.mean(y_pred[-config.relevant_prediction_tail:]))\n\nfor trace_id, (y_true, y_pred) in trace_forecast[\"out_of_distribution\"].items():\n    trace_means[\"out_of_distribution\"][\"ground_truth\"].append(np.mean(y_true[-config.relevant_prediction_tail:]))\n    trace_means[\"out_of_distribution\"][\"forecast\"].append(np.mean(y_pred[-config.relevant_prediction_tail:]))\n\n# Compute RMSE with standard error\nrmse_id, se_rmse_id = rmse_with_standard_error(\n    np.array(trace_means[\"in_distribution\"][\"ground_truth\"]),\n    np.array(trace_means[\"in_distribution\"][\"forecast\"]),\n)\nrmse_ood, se_rmse_ood = rmse_with_standard_error(\n    np.array(trace_means[\"out_of_distribution\"][\"ground_truth\"]),\n    np.array(trace_means[\"out_of_distribution\"][\"forecast\"]),\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\"CHRONOS-BOLT-TINY FEW-SHOT (k={config.k_shot}) RESULTS\")\nprint(\"=\"*60)\nprint(f\"ID RMSE:  {rmse_id:.4f} ± {se_rmse_id:.4f}\")\nprint(f\"OOD RMSE: {rmse_ood:.4f} ± {se_rmse_ood:.4f}\")\nprint(\"\\nZero-shot baseline:\")\nprint(\"ID RMSE:  87.78 ± 13.76\")\nprint(\"OOD RMSE: 68.02 ± 13.00\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing OOD: ood_iteration_0_ifft_realpotens\n",
      "Processing OOD: ood_iteration_1_ifft_realpotens\n",
      "Processing OOD: ood_iteration_2_ifft_realpotens\n",
      "Processing OOD: ood_iteration_3_ifft_realpotens\n",
      "Processing OOD: ood_iteration_4_ifft_realpotens\n"
     ]
    }
   ],
   "source": [
    "for trace_id in OUT_OF_DISTRIBUTION_ITERATIONS:\n",
    "    print(f\"Processing OOD: {trace_id}\")\n",
    "    trace = provider.get_ood(trace_id).numpy()\n",
    "    examples = select_examples_random(example_pool, k=config.k_shot, seed=config.random_seed)\n",
    "    forecast = fewshot_autoregressive_forecast(trace, examples, config, pipeline)\n",
    "    trace_forecast[\"out_of_distribution\"][trace_id] = (trace, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: /Users/lukaskurz/University/fusiontimeseries/results/few_shot/20260105_183807_amazon_chronos-bolt-tiny_k3_fewshot_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "model_name_clean = config.model_slug.replace(\"/\", \"_\")\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results = {\n",
    "    \"timestamp\": timestamp,\n",
    "    \"config\": config.model_dump(),\n",
    "    \"in_distribution\": {\"rmse\": float(rmse_id), \"se_rmse\": float(se_rmse_id), \"n_samples\": 6},\n",
    "    \"out_of_distribution\": {\"rmse\": float(rmse_ood), \"se_rmse\": float(se_rmse_ood), \"n_samples\": 5},\n",
    "}\n",
    "\n",
    "# Save to project root / results / few_shot\n",
    "data_dir = Path(\".\").resolve().parent.parent.parent.parent / \"results\" / \"few_shot\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_file = data_dir / f\"{timestamp}_{model_name_clean}_k{config.k_shot}_fewshot_results.json\"\n",
    "with open(results_file, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"Results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved to: /Users/lukaskurz/University/fusiontimeseries/results/few_shot/plots/20260105_183807_amazon_chronos-bolt-tiny_k3\n",
      "Total plots: 11\n"
     ]
    }
   ],
   "source": [
    "# Generate plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plots_dir = data_dir / \"plots\" / f\"{timestamp}_{model_name_clean}_k{config.k_shot}\"\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Plot ID traces\n",
    "for trace_id, (y_true, y_pred) in trace_forecast[\"in_distribution\"].items():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_true, label=\"Ground Truth\", linewidth=2, alpha=0.7)\n",
    "    plt.plot(y_pred, label=f\"Few-Shot (k={config.k_shot})\", linewidth=2, alpha=0.7, linestyle=\"--\")\n",
    "    plt.axvline(x=config.start_context_length, color=\"red\", linestyle=\":\", label=\"Forecast Start\", alpha=0.5)\n",
    "    plt.xlabel(\"Timestamp\")\n",
    "    plt.ylabel(\"Flux Value\")\n",
    "    plt.title(f\"{config.model_slug} Few-Shot (k={config.k_shot}) - ID: {trace_id}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / f\"id_{trace_id}.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# Plot OOD traces\n",
    "for trace_id, (y_true, y_pred) in trace_forecast[\"out_of_distribution\"].items():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_true, label=\"Ground Truth\", linewidth=2, alpha=0.7)\n",
    "    plt.plot(y_pred, label=f\"Few-Shot (k={config.k_shot})\", linewidth=2, alpha=0.7, linestyle=\"--\")\n",
    "    plt.axvline(x=config.start_context_length, color=\"red\", linestyle=\":\", label=\"Forecast Start\", alpha=0.5)\n",
    "    plt.xlabel(\"Timestamp\")\n",
    "    plt.ylabel(\"Flux Value\")\n",
    "    plt.title(f\"{config.model_slug} Few-Shot (k={config.k_shot}) - OOD: {trace_id}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / f\"ood_{trace_id}.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Plots saved to: {plots_dir}\")\n",
    "print(f\"Total plots: {len(trace_forecast['in_distribution']) + len(trace_forecast['out_of_distribution'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: /Users/lukaskurz/University/fusiontimeseries/src/results/few_shot/20260105_183810_amazon_chronos-bolt-tiny_k3_fewshot_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "model_name_clean = config.model_slug.replace(\"/\", \"_\")\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results = {\n",
    "    \"timestamp\": timestamp,\n",
    "    \"config\": config.model_dump(),\n",
    "    \"in_distribution\": {\"rmse\": float(rmse_id), \"se_rmse\": float(se_rmse_id), \"n_samples\": 6},\n",
    "    \"out_of_distribution\": {\"rmse\": float(rmse_ood), \"se_rmse\": float(se_rmse_ood), \"n_samples\": 5},\n",
    "}\n",
    "\n",
    "data_dir = Path(\".\").resolve().parent.parent.parent / \"results\" / \"few_shot\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_file = data_dir / f\"{timestamp}_{model_name_clean}_k{config.k_shot}_fewshot_results.json\"\n",
    "with open(results_file, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"Results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusiontimeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}